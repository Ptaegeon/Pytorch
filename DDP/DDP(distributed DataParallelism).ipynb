{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNycflwXxn3VhmudmTOKniJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0POAQNIs5aO-"},"outputs":[],"source":["!git clone https://github.com/pytorch/examples.git"]},{"cell_type":"code","source":["!pip install -r /content/examples/mnist/requirements.txt"],"metadata":{"id":"7hRObp6J5yaq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/examples/mnist/main.py --epochs 1"],"metadata":{"id":"eBEUff7e6U5r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\"\n","os.environ[\"MASTER_PORT\"] = args.port\n","os.environ[\"WORLD_SIZE\"] = args.world_size\n","os.environ[\"RANK\"] = args.rank"],"metadata":{"id":"dJgCfpr770EI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BV1ZNbt4BY70","executionInfo":{"status":"ok","timestamp":1663394228501,"user_tz":-540,"elapsed":19,"user":{"displayName":"bong bong","userId":"17774416216702601338"}},"outputId":"e0212a11-b11b-4585-c0d5-ecc81de32aef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.7.14\n"]}]},{"cell_type":"code","source":["import torch\n","for i in range(torch.cuda.device_count()):\n","    print(f'torch.cuda.get_device_properties({i}) : {torch.cuda.get_device_properties(i)}',\n","    f'torch.cuda.device_count() : {torch.cuda.device_count()}',\n","    f'torch.cuda.current_device() : {torch.cuda.current_device()}',\n","    f'torch.cuda.memory_allocated({i}) : {round(torch.cuda.memory_allocated(i)/1024**3,1)} GB',\n","    f'torch.cuda.memory_cached({i}) : {round(torch.cuda.memory_cached(i)/1024**3,1)} GB', sep='\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adNFvGnI9xlP","executionInfo":{"status":"ok","timestamp":1663394746250,"user_tz":-540,"elapsed":372,"user":{"displayName":"bong bong","userId":"17774416216702601338"}},"outputId":"2fee2bd2-51d2-4f19-ac95-84f564a51e83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.cuda.get_device_properties(0) : _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n","torch.cuda.device_count() : 1\n","torch.cuda.current_device() : 0\n","torch.cuda.memory_allocated(0) : 0.0 GB\n","torch.cuda.memory_cached(0) : 0.0 GB\n"]}]},{"cell_type":"code","source":["import torch\n","\"\"\"\n","arg.distributed : node가 2개 이상일때 True, multi machine\n","                    node가 1개 : single machine\n","\n","\"\"\"\n"," # 내용3: multiprocess 설정\n","if arg.distributed:\n","    nnode = arg.nnod if arg.nnod >1 else 1  \n","\n","    if torch.cuda.is_available():\n","        ngpus_per_node = torch.cuda.device_count()\n","        world_size = ngpus_per_node * nnode\n","        batch_size = int(batch_size / world_size)\n","        workers = int((workers + world_size - 1) / world_size)\n","\n","        for i in range(ngpus_per_node):\n","            model.cuda(i)\n","            model = torch.nn.parallel.DistributedDataParallel(model,device_ids=[i]) # device_ids = gpu, 0,1,2,...\n","            # args.gpu : 0,1,2,3...\n","        \"\"\"\n","        model.cuda()\n","        model = torch.nn.parallel.DistributedDataParallel(model)\n","        # 만약에 device_ids를 따로 설정해주지 않으면, 가능한 모든 gpu를 기준으로 \n","            ddp가 알아서 배치사이즈와 workers를 나눠준다\n","        \n","        \"\"\"\n","    elif args.gpu is not None:\n","        torch.cuda.set_device(args.gpu)\n","        model=model.cuda(args.gpu)\n","        raise NotImplementedError(\"Only DistributedDataParallel is supported.\")\n","    else:\n","        raise NotImplementedError(\"Only DistributedDataparallel is supported.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"id":"OJLqGEbf9kbt","executionInfo":{"status":"error","timestamp":1663393267490,"user_tz":-540,"elapsed":2529,"user":{"displayName":"bong bong","userId":"17774416216702601338"}},"outputId":"3288a62d-ac9b-4b5a-839e-6d44aefeaeb1"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-a165652cba8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# 만약에 device_ids를 따로 설정해주지 않으면, 가능한 모든 gpu를 기준으로 ddp가 알아서 배치사이즈와 workers를 나눠준다는 뜻.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"]}]},{"cell_type":"code","source":["criterion.cuda(arg.gpu)"],"metadata":{"id":"dXhZMLMIFxfq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"4CrxF1QxKoYP"}},{"cell_type":"code","source":["if arg.distributed:\n","    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n","else :\n","    train_sampler = None\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                           batch_size=args.batch_size,\n","                                           shuffle=(train_sampler is None),\n","                                           num_workers=args.workers,\n","                                           pin_memory=True,\n","                                           sampler=train_sampler)\n","val_loader = torch.utils.data.DataLoader(val_dataset,\n","                                         batch_size=args.batch_size,\n","                                         shuffle=False,\n","                                         num_workers=args.workers,\n","                                         pin_memory=True)"],"metadata":{"id":"Ihw1xfh7Hrdl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cudnn.benchmark = True\n","stime = time.time()\n","scaler = torch.cuda.amp.GradScaler()\n","for epoch in range(args.start_epoch, args.epochs):\n","    # 내용 6-1: train_sampler.set_epoch\n","    # In distributed mode, calling the set_eopch() method at the beggining of \n","    # each epoch before creating the \"dataloader\" iterator is necessary to make\n","    # suffling work properly across multiple epochs. Otherwise, the same ordering will be always used.\n","    if args.distributed:\n","        train_sampler.set_epoch(epoch)\n","\n"],"metadata":{"id":"na5Xe3BnIRJr"},"execution_count":null,"outputs":[]}]}